{"cells":[{"cell_type":"markdown","metadata":{"id":"VQS2S6LAYEbT"},"source":["**Este notebook Necesita correrse con GPU**\n","\n","This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n","\n","**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n","\n","This notebook was generated for TensorFlow 2.6."]},{"cell_type":"markdown","metadata":{"id":"23RdNR33YEbb"},"source":["# Deep learning for text"]},{"cell_type":"markdown","metadata":{"id":"kQYucmcVYEbd"},"source":["## Natural-language processing: The bird's eye view"]},{"cell_type":"markdown","metadata":{"id":"C37psuwpYEbi"},"source":["## Preparing text data"]},{"cell_type":"markdown","metadata":{"id":"iDrk_HHwYEbn"},"source":["### Text standardization"]},{"cell_type":"markdown","metadata":{"id":"QPm0vKpVYEbs"},"source":["### Text splitting (tokenization)"]},{"cell_type":"markdown","metadata":{"id":"Pmy5PspVYEbz"},"source":["### Vocabulary indexing"]},{"cell_type":"markdown","metadata":{"id":"-T8w2j5lYEb1"},"source":["### Using the TextVectorization layer"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"4MlAqu-4YEb4","executionInfo":{"status":"ok","timestamp":1651622610249,"user_tz":300,"elapsed":12,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["import string\n","\n","class Vectorizer:\n","    def standardize(self, text):\n","        text = text.lower()\n","        return \"\".join(char for char in text if char not in string.punctuation)\n","\n","    def tokenize(self, text):\n","        text = self.standardize(text)\n","        return text.split()\n","\n","    def make_vocabulary(self, dataset):\n","        self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n","        for text in dataset:\n","            text = self.standardize(text)\n","            tokens = self.tokenize(text)\n","            for token in tokens:\n","                if token not in self.vocabulary:\n","                    self.vocabulary[token] = len(self.vocabulary)\n","        self.inverse_vocabulary = dict(\n","            (v, k) for k, v in self.vocabulary.items())\n","\n","    def encode(self, text):\n","        text = self.standardize(text)\n","        tokens = self.tokenize(text)\n","        return [self.vocabulary.get(token, 1) for token in tokens]\n","\n","    def decode(self, int_sequence):\n","        return \" \".join(\n","            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n","\n","vectorizer = Vectorizer()\n","dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","vectorizer.make_vocabulary(dataset)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"B5eJF_4XYEcA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622610251,"user_tz":300,"elapsed":11,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"dc371ca8-ed9f-4639-b185-6ca5dc39726f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 3, 5, 7, 1, 5, 6]\n"]}],"source":["test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = vectorizer.encode(test_sentence)\n","print(encoded_sentence)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1T9bfgdEYEcR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622611671,"user_tz":300,"elapsed":30,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"7574dcd0-feb2-4735-c0a6-b0d5e2dc5155"},"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}],"source":["decoded_sentence = vectorizer.decode(encoded_sentence)\n","print(decoded_sentence)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"q8Vu5E2UYEcW","executionInfo":{"status":"ok","timestamp":1651622620092,"user_tz":300,"elapsed":7782,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["from tensorflow.keras.layers import TextVectorization\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lfQVRwWkYEcY","executionInfo":{"status":"ok","timestamp":1651622620098,"user_tz":300,"elapsed":22,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["import re\n","import string\n","import tensorflow as tf\n","\n","def custom_standardization_fn(string_tensor):\n","    lowercase_string = tf.strings.lower(string_tensor)\n","    return tf.strings.regex_replace(\n","        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n","\n","def custom_split_fn(string_tensor):\n","    return tf.strings.split(string_tensor)\n","\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n","    standardize=custom_standardization_fn,\n","    split=custom_split_fn,\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"qzJ21lA8YEca","executionInfo":{"status":"ok","timestamp":1651622621236,"user_tz":300,"elapsed":1154,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","text_vectorization.adapt(dataset)"]},{"cell_type":"markdown","metadata":{"id":"QFYBuM4_YEcc"},"source":["**Displaying the vocabulary**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Gs3I-rlHYEce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622621241,"user_tz":300,"elapsed":31,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"e14904d2-4bf1-4b6c-9bf2-74d7b4e620eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '[UNK]',\n"," 'erase',\n"," 'write',\n"," 'then',\n"," 'rewrite',\n"," 'poppy',\n"," 'i',\n"," 'blooms',\n"," 'and',\n"," 'again',\n"," 'a']"]},"metadata":{},"execution_count":7}],"source":["text_vectorization.get_vocabulary()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6TfTR3drYEch","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622621824,"user_tz":300,"elapsed":600,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"62f6ee18-7dd8-4727-f0f1-8e124098f3c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"]}],"source":["vocabulary = text_vectorization.get_vocabulary()\n","test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = text_vectorization(test_sentence)\n","print(encoded_sentence)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Jo9zVB_eYEcj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622621827,"user_tz":300,"elapsed":24,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"5f6aa2d6-0681-4905-9d54-ae82d586df82"},"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}],"source":["inverse_vocab = dict(enumerate(vocabulary))\n","decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n","print(decoded_sentence)"]},{"cell_type":"markdown","metadata":{"id":"_a2uS8ojYEcl"},"source":["## Two approaches for representing groups of words: Sets and sequences"]},{"cell_type":"markdown","metadata":{"id":"ZJWcrU4rYEcm"},"source":["### Preparing the IMDB movie reviews data"]},{"cell_type":"code","source":["aqui se cragan los datos "],"metadata":{"id":"YK5KN7CZYTq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Q0dBHgILYEcn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622633931,"user_tz":300,"elapsed":12117,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"2227a979-856a-4566-9270-84f33e00953c"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  22.0M      0  0:00:03  0:00:03 --:--:-- 22.0M\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"v13q89gWYEcp","executionInfo":{"status":"ok","timestamp":1651622635569,"user_tz":300,"elapsed":1649,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["!rm -r aclImdb/train/unsup"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"gnYP_QsXYEcq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622635795,"user_tz":300,"elapsed":238,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"4f44c09c-5cf5-4802-a985-d8343d2b7b09"},"outputs":[{"output_type":"stream","name":"stdout","text":["I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"]}],"source":["!cat aclImdb/train/pos/4077_10.txt"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Fk6ENSwjYEcr","executionInfo":{"status":"ok","timestamp":1651622636413,"user_tz":300,"elapsed":625,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["import os, pathlib, shutil, random\n","\n","base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category)\n","    files = os.listdir(train_dir / category)\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:]\n","    for fname in val_files:\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"cJq0iyMPYEcu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622644476,"user_tz":300,"elapsed":2881,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"a91f0c91-da27-4cff-86f8-7a11052d96a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}],"source":["from tensorflow import keras\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size=batch_size\n",")"]},{"cell_type":"markdown","metadata":{"id":"DKWg7Q00YEcv"},"source":["**Displaying the shapes and dtypes of the first batch**"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"BOUHe6ejYEcx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622644480,"user_tz":300,"elapsed":25,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"872a5b54-c593-46e3-cfd8-92eec1a2d2f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32,)\n","inputs.dtype: <dtype: 'string'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor(b'As for many on here I can\\'t help but praise the Cast and Crew who developed Talespin and others they made throughout My Childhood, I as all who have commented here have thoroughly enjoyed the Quality of not just the animation but the quality of the story lines and the characters.<br /><br />To Class this work of art as a \"Cartoon\" could never do talespin justice, In fact it\\'s an insult to class it as a \"Cartoon\", Talespin is an Animation and nothing less, It is evidently the greatest work of genius to be produced at Disney to date, When Disney \"Pulled\" it from the air little did they realise what they did and I\\'m sure their souls have been tortured by regret ever since.<br /><br />I\\'ll take a moment to explain, From the first which is ducktales to the last which I think is Darkwing Duck, Disney has been plagued with failures due to political Correctness and have taken a Quantum Leap backwards since, They prefer Quantity over Quality now not to mention the room full of Monkey\\'s for the story\\'s, I couldn\\'t have My children watching the mind-numbing \"Cartoons\" they throw out now in fear that they would all turn out to be homer Simpson some time in the future and 50% of the blame would be on me for permitting them to watch it, I couldn\\'t let that happen, Which is why I have ALL of the shows from the late 80\\'s to the mid 90\\'s on a Harddrive so one day My children couldn\\'t be corrupted by the \"Cartoon Crap\" of today and to Savour the last piece of childhood I have and to hold on to and I owe that all to Talespin.<br /><br />Talespin to me is without a doubt the best Animation ever produced in the world on account of it\\'s depth, Charm, Wit, Compassion, Emotion and lack of Truly bad quality and story lines of which many have today, Do You see any of that content in say \"Ed, Edd and Eddie or anything else You can think of?, The rubbish produced today can be likened to some 3 year old\\'s undecipherable Hyroglyph Depicting a Picasso.<br /><br />The next time You watch an episode of Talespin; take a look at the woodgrain on any wooden object or building such as Higher for Hire and salivate over the quality of workmanship and effort put into this Animation, Even the one shot backgrounds were done as though they would use them again and again, The Buildings look true to the Art Deco movement which was popular in the time period depicted, Even the vehicles are true to life, OK not ALL of the Episodes Were Fantastic in animation but the lower grade scenes were covered up by the superior scenes so all in all it evened it all out by the end of the episode and You\\'d probably never even notice at all unless you were focused and have an attention to detail.<br /><br />The one thing I love about this is what I like to call the \"Deliberate Mistakes\" or \"Intended Mistakes\" in each episode and some have two, For example in sheepskin deep where rebecca say\\'s \"You\\'re up to something Baloo\" and Baloo replies \"Who, Me!, I\\'m as innocent as a schoolboy\" take a look into rebecca\\'s eyes, I won\\'t spoil the rest of the Baloopers but just keep an Eye out next time.<br /><br />Everyone elses comment\\'s are bang on and 100% correct, I have nothing else to add that others haven\\'t said already on here, Disney, WAKE UP and smell the coffee, You have been asleep for over a decade, Stop producing rubbish and bring back Quality into Animations and Stop producing \"Cartoons\", We have seen the proof of what You can do and We want it back as rapidly as possible.', shape=(), dtype=string)\n","targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"]}],"source":["for inputs, targets in train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"iulTD8uFYEcz"},"source":["### Processing words as a set: The bag-of-words approach"]},{"cell_type":"markdown","metadata":{"id":"mr2NA3VzYEc0"},"source":["#### Single words (unigrams) with binary encoding"]},{"cell_type":"markdown","metadata":{"id":"iksP0N7EYEc2"},"source":["**Preprocessing our datasets with a `TextVectorization` layer**"]},{"cell_type":"markdown","source":["No se considera el orden y lo haremos con unigramos, y las palabras sufriran un one hot encodig. Con el unigramo solo separamos en conjuntos de una palabra "],"metadata":{"id":"5WVyVI-iY2f5"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"gBvseQbJYEc2","executionInfo":{"status":"ok","timestamp":1651622650545,"user_tz":300,"elapsed":5421,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\",\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)\n","\n","binary_1gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_1gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_1gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"]},{"cell_type":"markdown","metadata":{"id":"wphhNSF0YEc4"},"source":["**Inspecting the output of our binary unigram dataset**"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"FvAUNK0LYEc6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622650801,"user_tz":300,"elapsed":265,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"38fbf01c-8ed1-4c27-87bf-38006c09cecc"},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32, 20000)\n","inputs.dtype: <dtype: 'float32'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n","targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"]}],"source":["for inputs, targets in binary_1gram_train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"Z6Eu5jhDYEc7"},"source":["**Our model-building utility**"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"2fmoOiXIYEc8","executionInfo":{"status":"ok","timestamp":1651622650802,"user_tz":300,"elapsed":9,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def get_model(max_tokens=20000, hidden_dim=16):\n","    inputs = keras.Input(shape=(max_tokens,))\n","    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","    model = keras.Model(inputs, outputs)\n","    model.compile(optimizer=\"rmsprop\",\n","                  loss=\"binary_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"betXP3YkYEdD"},"source":["**Training and testing the binary unigram model**"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"7ncweyyHYEdL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622711454,"user_tz":300,"elapsed":57587,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"9726aafc-e014-4291-d6d6-624a4a975db5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense (Dense)               (None, 16)                320016    \n","                                                                 \n"," dropout (Dropout)           (None, 16)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 11s 12ms/step - loss: 0.4123 - accuracy: 0.8296 - val_loss: 0.2869 - val_accuracy: 0.8862\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2706 - accuracy: 0.9054 - val_loss: 0.2725 - val_accuracy: 0.8958\n","Epoch 3/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2467 - accuracy: 0.9160 - val_loss: 0.2858 - val_accuracy: 0.8952\n","Epoch 4/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2281 - accuracy: 0.9242 - val_loss: 0.3094 - val_accuracy: 0.8872\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2215 - accuracy: 0.9270 - val_loss: 0.3119 - val_accuracy: 0.8892\n","Epoch 6/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2101 - accuracy: 0.9324 - val_loss: 0.3225 - val_accuracy: 0.8896\n","Epoch 7/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2116 - accuracy: 0.9353 - val_loss: 0.3346 - val_accuracy: 0.8852\n","Epoch 8/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2073 - accuracy: 0.9353 - val_loss: 0.3385 - val_accuracy: 0.8838\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2006 - accuracy: 0.9353 - val_loss: 0.3464 - val_accuracy: 0.8888\n","Epoch 10/10\n","625/625 [==============================] - 2s 4ms/step - loss: 0.2039 - accuracy: 0.9389 - val_loss: 0.3565 - val_accuracy: 0.8898\n","782/782 [==============================] - 7s 9ms/step - loss: 0.2901 - accuracy: 0.8872\n","Test acc: 0.887\n"]}],"source":["model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(binary_1gram_train_ds.cache(),\n","          validation_data=binary_1gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_1gram.keras\")\n","print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"X2pH4i_DYEdM"},"source":["#### Bigrams with binary encoding\n","\n","Modelo con Bigramos, es decir, conjuntos de 2 palabras4\n"]},{"cell_type":"markdown","metadata":{"id":"L2_F26y7YEdO"},"source":["**Configuring the `TextVectorization` layer to return bigrams**"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"HaEXD_3WYEdP","executionInfo":{"status":"ok","timestamp":1651622711457,"user_tz":300,"elapsed":40,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"WOT3TyDyYEdR"},"source":["**Training and testing the binary bigram model**"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"s9vMPGwWYEdS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651622836154,"user_tz":300,"elapsed":59466,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"44e2fda8-6ad8-4c5e-9173-5c45b280fe7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense_2 (Dense)             (None, 16)                320016    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 8s 12ms/step - loss: 0.3886 - accuracy: 0.8397 - val_loss: 0.2687 - val_accuracy: 0.8962\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2469 - accuracy: 0.9123 - val_loss: 0.2651 - val_accuracy: 0.9034\n","Epoch 3/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2115 - accuracy: 0.9293 - val_loss: 0.2808 - val_accuracy: 0.8998\n","Epoch 4/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1939 - accuracy: 0.9398 - val_loss: 0.2995 - val_accuracy: 0.9000\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1821 - accuracy: 0.9445 - val_loss: 0.3213 - val_accuracy: 0.8998\n","Epoch 6/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1874 - accuracy: 0.9484 - val_loss: 0.3280 - val_accuracy: 0.8972\n","Epoch 7/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1864 - accuracy: 0.9486 - val_loss: 0.3404 - val_accuracy: 0.8972\n","Epoch 8/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1761 - accuracy: 0.9513 - val_loss: 0.3485 - val_accuracy: 0.8944\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1775 - accuracy: 0.9517 - val_loss: 0.3618 - val_accuracy: 0.8922\n","Epoch 10/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1708 - accuracy: 0.9531 - val_loss: 0.3700 - val_accuracy: 0.8916\n","782/782 [==============================] - 7s 9ms/step - loss: 0.2680 - accuracy: 0.9021\n","Test acc: 0.902\n"]}],"source":["text_vectorization.adapt(text_only_train_ds)\n","binary_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(binary_2gram_train_ds.cache(),\n","          validation_data=binary_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_2gram.keras\")\n","print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"-A0UKUOIYEdT"},"source":["#### Bigrams with TF-IDF encoding\n","\n","Decodificacion que mejora el aproach del modelo"]},{"cell_type":"markdown","metadata":{"id":"STB4-6CMYEdV"},"source":["**Configuring the `TextVectorization` layer to return token counts**"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"N9VNG7J7YEdX","executionInfo":{"status":"ok","timestamp":1651623208104,"user_tz":300,"elapsed":164,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"count\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"Vq6ar6zgYEdY"},"source":["**Configuring `TextVectorization` to return TF-IDF-weighted outputs**"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"xjM1DD84YEdZ","executionInfo":{"status":"ok","timestamp":1651623433041,"user_tz":300,"elapsed":151,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}}},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"tf_idf\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"CB-ldYonYEda"},"source":["**Training and testing the TF-IDF bigram model**"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"z3wCuNuaYEdb","colab":{"base_uri":"https://localhost:8080/","height":538},"executionInfo":{"status":"error","timestamp":1651623434442,"user_tz":300,"elapsed":360,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"65524229-b3f6-4927-d298-885ca9fbdd97"},"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-09c5afe5a363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_vectorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_only_train_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m tfidf_2gram_train_ds = train_ds.map(\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext_vectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     num_parallel_calls=4)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    426\u001b[0m           \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0marray\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n\t [[{{node map/TensorArrayUnstack/TensorListFromTensor/_42}}]]\n\t [[Func/map/while/body/_1/input/_47/_60]]\n  (1) INVALID_ARGUMENT:  During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n\t [[{{node map/TensorArrayUnstack/TensorListFromTensor/_42}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_adapt_step_75419]"]}],"source":["text_vectorization.adapt(text_only_train_ds)\n","\n","tfidf_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(tfidf_2gram_train_ds.cache(),\n","          validation_data=tfidf_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"tfidf_2gram.keras\")\n","print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"7cFu0AouYEdc","colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"status":"error","timestamp":1651623344205,"user_tz":300,"elapsed":201,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"10a23ac5-7430-47ed-831c-e5c97cd4c32c"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-ac353ac87999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_vectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minference_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/preprocessing/index_lookup.py\u001b[0m in \u001b[0;36m_maybe_freeze_vocab_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m           \u001b[0;34m\"must set the layer's vocabulary before calling it. Either pass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m           \u001b[0;34m\"a `vocabulary` argument to the layer, or call `adapt` with some \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m           \"sample data.\".format(self.output_mode))\n\u001b[0m\u001b[1;32m    756\u001b[0m     elif (self._frozen_vocab_size is not None and\n\u001b[1;32m    757\u001b[0m           new_vocab_size != self._frozen_vocab_size):\n","\u001b[0;31mRuntimeError\u001b[0m: Exception encountered when calling layer \"string_lookup_5\" (type StringLookup).\n\nWhen using `output_mode=tf_idf` and `pad_to_max_tokens=False`, you must set the layer's vocabulary before calling it. Either pass a `vocabulary` argument to the layer, or call `adapt` with some sample data.\n\nCall arguments received:\n  • inputs=tf.RaggedTensor(values=Tensor(\"text_vectorization_5/StringNGrams/StringNGrams:0\", shape=(None,), dtype=string), row_splits=Tensor(\"text_vectorization_5/StringNGrams/StringNGrams:1\", shape=(None,), dtype=int64))"]}],"source":["inputs = keras.Input(shape=(1,), dtype=\"string\")\n","processed_inputs = text_vectorization(inputs)\n","outputs = model(processed_inputs)\n","inference_model = keras.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"9YVu9DXvYEde","colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"status":"error","timestamp":1651623212254,"user_tz":300,"elapsed":187,"user":{"displayName":"Jonathan Ramírez","userId":"09469315614794190682"}},"outputId":"2b586e35-d809-435e-d94a-1eccb9077c79"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-be255e1a4ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"That was an excellent movie, I loved it.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{float(predictions[0] * 100):.2f} percent positive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'inference_model' is not defined"]}],"source":["import tensorflow as tf\n","raw_text_data = tf.convert_to_tensor([\n","    [\"That was an excellent movie, I loved it.\"],\n","])\n","predictions = inference_model(raw_text_data)\n","print(f\"{float(predictions[0] * 100):.2f} percent positive\")"]},{"cell_type":"code","source":[""],"metadata":{"id":"jMyrc6mdajLl"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"cl7PNL.ipynb","provenance":[{"file_id":"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part01_introduction.ipynb","timestamp":1651622571365}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}